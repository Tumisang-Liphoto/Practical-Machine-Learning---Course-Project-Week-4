---
title: "Prediction Assignment Writeup"
author: "Liphoto"
date: "12/28/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r library setup}

library(caret)
library(rpart)
library(rpart.plot)
library(randomForest)
library(corrplot)
library(rattle)
library(lattice)
library(ggplot2)
library(kernlab)
library(corrplot)

set.seed(1234) # there will be some randomization thus we set a seed

```


```{r dataset Preparation}

# set the URL for the download
UrlTrain <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
UrlTest  <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

# download the datasets
training <- read.csv(url(UrlTrain))
testing  <- read.csv(url(UrlTest))

```

```{r summarise the data}
#str(training)
#str(testing)
#summary(training)
#summary(testing)
dim(training)
dim(testing)

```
# Data Preparations
1. We see that the data contains some N/A values, we thus do some data wrangling to remove the N/A s.


```{r remove N/A s}


sum(complete.cases(training))


training <- training[, colSums(is.na(training)) == 0] 
testing <- testing[, colSums(is.na(testing)) == 0]

dim(training)
dim(testing)




```

2. Data Partitioning
Because I want to be able to estimate the out-of-sample error, I randomly split the training data into a smaller training set  and a validation set

```{r data partitioning}
trainingData <- createDataPartition(y=training$classe, p=0.7, list=FALSE)
trainingData1 <- training[trainingData, ]
trainingData2 <- training[-trainingData, ]
```

3. Some of the variables are of no consequence [X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp], eliminate them

```{r remove errelevant data}
trainingData1 <- trainingData1[, -(1:5)]
trainingData2 <- trainingData2[, -(1:5)]
dim(trainingData1)
dim(trainingData2)
```

# Data Modeling

```{r}
control <- trainControl(method="cv", number=3, verboseIter=F)
```


1. Decision trees with CART (rpart)

```{r Decision tree}

mod_trees <- train(classe~., data=trainingData1, method="rpart", trControl = control, tuneLength = 5)
fancyRpartPlot(mod_trees$finalModel)

```


```{r prediction}

pred_trees <- predict(mod_trees, trainingData2)
cmtrees <- confusionMatrix(pred_trees, factor(trainingData2$classe))
cmtrees

```






